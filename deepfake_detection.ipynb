{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Adn8U10XS2If"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vhWA9cmLfBot"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./Generative AI Dataset/Dataset/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EhNFrFuq6JA",
    "outputId": "fea8fc24-3c9f-4b67-e58f-b3c22a3ec96b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1190</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.111266</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735240</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104698</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360237</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416629</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>0</td>\n",
       "      <td>1.157565</td>\n",
       "      <td>-0.142219</td>\n",
       "      <td>1.043992</td>\n",
       "      <td>1.144946</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>-1.505100</td>\n",
       "      <td>-0.874137</td>\n",
       "      <td>-1.782724</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.255793</td>\n",
       "      <td>-0.154838</td>\n",
       "      <td>0.413029</td>\n",
       "      <td>-0.482939</td>\n",
       "      <td>-1.277953</td>\n",
       "      <td>-0.445082</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.924614</td>\n",
       "      <td>-0.432462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>0</td>\n",
       "      <td>1.424709</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>1.356778</td>\n",
       "      <td>1.368099</td>\n",
       "      <td>-0.318862</td>\n",
       "      <td>1.039765</td>\n",
       "      <td>-0.986854</td>\n",
       "      <td>-0.330184</td>\n",
       "      <td>-1.383120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424709</td>\n",
       "      <td>-1.066107</td>\n",
       "      <td>0.881258</td>\n",
       "      <td>-0.488691</td>\n",
       "      <td>-1.281223</td>\n",
       "      <td>-1.213291</td>\n",
       "      <td>0.122692</td>\n",
       "      <td>1.175627</td>\n",
       "      <td>-1.145360</td>\n",
       "      <td>0.451026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.375687</td>\n",
       "      <td>1.524455</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>-0.906909</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>1.606182</td>\n",
       "      <td>0.298557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028349</td>\n",
       "      <td>-0.968204</td>\n",
       "      <td>-1.233815</td>\n",
       "      <td>1.626613</td>\n",
       "      <td>-0.191802</td>\n",
       "      <td>1.115823</td>\n",
       "      <td>0.380284</td>\n",
       "      <td>-0.293960</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>1.381434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.478238</td>\n",
       "      <td>1.666142</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-0.362771</td>\n",
       "      <td>1.798104</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-1.121552</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>-0.593705</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>1.765114</td>\n",
       "      <td>0.313533</td>\n",
       "      <td>-0.329781</td>\n",
       "      <td>-1.220524</td>\n",
       "      <td>0.033114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.750874</td>\n",
       "      <td>0.267008</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.179867</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.279173</td>\n",
       "      <td>1.731765</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.850180</td>\n",
       "      <td>0.937321</td>\n",
       "      <td>-1.594972</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>1.582807</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>-0.254346</td>\n",
       "      <td>0.664230</td>\n",
       "      <td>1.831071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
       "0          0 -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562   \n",
       "1          1 -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930   \n",
       "2          1  0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321   \n",
       "3          0  1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307   \n",
       "4          0  0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "5245       0  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978   \n",
       "5246       0  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765   \n",
       "5247       1 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909   \n",
       "5248       1 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104   \n",
       "5249       1 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999   \n",
       "\n",
       "           f_6       f_7       f_8  ...    f_1190    f_1191    f_1192  \\\n",
       "0    -0.196530 -0.125239 -0.452284  ... -1.111266  0.716084  0.060039   \n",
       "1    -1.680658 -0.358146  0.166122  ...  0.735240  0.829781  1.521941   \n",
       "2    -1.493958  0.789572 -1.311018  ...  0.104698  0.616189 -1.035953   \n",
       "3     0.605559 -0.019024  1.065448  ...  0.360237 -1.957863 -0.123384   \n",
       "4     0.193832  1.035091 -0.538868  ...  0.416629  1.441766  0.212572   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5245 -1.505100 -0.874137 -1.782724  ...  1.195423 -0.255793 -0.154838   \n",
       "5246 -0.986854 -0.330184 -1.383120  ...  1.424709 -1.066107  0.881258   \n",
       "5247 -1.254247  1.606182  0.298557  ... -0.028349 -0.968204 -1.233815   \n",
       "5248 -0.214314  0.775400 -0.379267  ... -0.428752 -1.121552 -0.379267   \n",
       "5249 -0.279173  1.731765  0.564925  ... -0.303999 -0.850180  0.937321   \n",
       "\n",
       "        f_1193    f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  \n",
       "0     0.301279 -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003  \n",
       "1     1.347946  0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870  \n",
       "2     2.111387 -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795  \n",
       "3     1.505329  0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116  \n",
       "4    -0.994721  1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5245  0.413029 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462  \n",
       "5246 -0.488691 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026  \n",
       "5247  1.626613 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434  \n",
       "5248 -0.593705  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114  \n",
       "5249 -1.594972  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071  \n",
       "\n",
       "[5250 rows x 1201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIG_jwq7qeJ_",
    "outputId": "28278bb5-f9af-4969-a536-76b5a946fc20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 1201)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9QKnqY3q3EJ",
    "outputId": "087734fb-fdde-43d8-cb9d-5c7d855abdc3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_1191</th>\n",
       "      <th>f_1192</th>\n",
       "      <th>f_1193</th>\n",
       "      <th>f_1194</th>\n",
       "      <th>f_1195</th>\n",
       "      <th>f_1196</th>\n",
       "      <th>f_1197</th>\n",
       "      <th>f_1198</th>\n",
       "      <th>f_1199</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.033875</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>-0.142131</td>\n",
       "      <td>-0.177117</td>\n",
       "      <td>-1.470684</td>\n",
       "      <td>1.669562</td>\n",
       "      <td>-0.196530</td>\n",
       "      <td>-0.125239</td>\n",
       "      <td>-0.452284</td>\n",
       "      <td>-0.128052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716084</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-1.174846</td>\n",
       "      <td>-1.076498</td>\n",
       "      <td>-0.069452</td>\n",
       "      <td>-0.604012</td>\n",
       "      <td>-2.179176</td>\n",
       "      <td>0.558003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.294815</td>\n",
       "      <td>-0.557577</td>\n",
       "      <td>-2.020773</td>\n",
       "      <td>-1.234715</td>\n",
       "      <td>1.633930</td>\n",
       "      <td>-1.680658</td>\n",
       "      <td>-0.358146</td>\n",
       "      <td>0.166122</td>\n",
       "      <td>-1.656990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829781</td>\n",
       "      <td>1.521941</td>\n",
       "      <td>1.347946</td>\n",
       "      <td>0.754505</td>\n",
       "      <td>1.330642</td>\n",
       "      <td>-0.754453</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.252671</td>\n",
       "      <td>1.495870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113248</td>\n",
       "      <td>-0.607726</td>\n",
       "      <td>-0.947791</td>\n",
       "      <td>0.830851</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.498321</td>\n",
       "      <td>-1.493958</td>\n",
       "      <td>0.789572</td>\n",
       "      <td>-1.311018</td>\n",
       "      <td>0.848524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616189</td>\n",
       "      <td>-1.035953</td>\n",
       "      <td>2.111387</td>\n",
       "      <td>-0.984415</td>\n",
       "      <td>1.148076</td>\n",
       "      <td>-1.433554</td>\n",
       "      <td>0.243372</td>\n",
       "      <td>0.170083</td>\n",
       "      <td>1.274795</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.223321</td>\n",
       "      <td>-0.479048</td>\n",
       "      <td>-1.925789</td>\n",
       "      <td>1.680377</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>-1.453307</td>\n",
       "      <td>0.605559</td>\n",
       "      <td>-0.019024</td>\n",
       "      <td>1.065448</td>\n",
       "      <td>0.717341</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.957863</td>\n",
       "      <td>-0.123384</td>\n",
       "      <td>1.505329</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>-1.769443</td>\n",
       "      <td>-0.547756</td>\n",
       "      <td>-0.568122</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>0.982116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.422684</td>\n",
       "      <td>-0.308029</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.432854</td>\n",
       "      <td>0.608348</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>-0.538868</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.441766</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>-0.994721</td>\n",
       "      <td>1.143999</td>\n",
       "      <td>-2.166923</td>\n",
       "      <td>-1.199248</td>\n",
       "      <td>-1.028636</td>\n",
       "      <td>0.752791</td>\n",
       "      <td>0.317169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>1.157565</td>\n",
       "      <td>-0.142219</td>\n",
       "      <td>1.043992</td>\n",
       "      <td>1.144946</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>0.248978</td>\n",
       "      <td>-1.505100</td>\n",
       "      <td>-0.874137</td>\n",
       "      <td>-1.782724</td>\n",
       "      <td>0.261597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255793</td>\n",
       "      <td>-0.154838</td>\n",
       "      <td>0.413029</td>\n",
       "      <td>-0.482939</td>\n",
       "      <td>-1.277953</td>\n",
       "      <td>-0.445082</td>\n",
       "      <td>1.195423</td>\n",
       "      <td>-0.924614</td>\n",
       "      <td>-0.432462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>1.424709</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>1.356778</td>\n",
       "      <td>1.368099</td>\n",
       "      <td>-0.318862</td>\n",
       "      <td>1.039765</td>\n",
       "      <td>-0.986854</td>\n",
       "      <td>-0.330184</td>\n",
       "      <td>-1.383120</td>\n",
       "      <td>1.243559</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.066107</td>\n",
       "      <td>0.881258</td>\n",
       "      <td>-0.488691</td>\n",
       "      <td>-1.281223</td>\n",
       "      <td>-1.213291</td>\n",
       "      <td>0.122692</td>\n",
       "      <td>1.175627</td>\n",
       "      <td>-1.145360</td>\n",
       "      <td>0.451026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>-0.375687</td>\n",
       "      <td>1.524455</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>-0.007917</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>-0.906909</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>1.606182</td>\n",
       "      <td>0.298557</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.968204</td>\n",
       "      <td>-1.233815</td>\n",
       "      <td>1.626613</td>\n",
       "      <td>-0.191802</td>\n",
       "      <td>1.115823</td>\n",
       "      <td>0.380284</td>\n",
       "      <td>-0.293960</td>\n",
       "      <td>0.135104</td>\n",
       "      <td>1.381434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>-0.478238</td>\n",
       "      <td>1.666142</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>-0.428752</td>\n",
       "      <td>-0.362771</td>\n",
       "      <td>1.798104</td>\n",
       "      <td>-0.214314</td>\n",
       "      <td>0.775400</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>0.725914</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.121552</td>\n",
       "      <td>-0.379267</td>\n",
       "      <td>-0.593705</td>\n",
       "      <td>0.049609</td>\n",
       "      <td>1.765114</td>\n",
       "      <td>0.313533</td>\n",
       "      <td>-0.329781</td>\n",
       "      <td>-1.220524</td>\n",
       "      <td>0.033114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>-0.750874</td>\n",
       "      <td>0.267008</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.179867</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.303999</td>\n",
       "      <td>-0.279173</td>\n",
       "      <td>1.731765</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>1.508328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850180</td>\n",
       "      <td>0.937321</td>\n",
       "      <td>-1.594972</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>1.582807</td>\n",
       "      <td>1.036626</td>\n",
       "      <td>-0.254346</td>\n",
       "      <td>0.664230</td>\n",
       "      <td>1.831071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0    -2.033875  0.978446 -0.142131 -0.177117 -1.470684  1.669562 -0.196530   \n",
       "1    -0.348835  0.294815 -0.557577 -2.020773 -1.234715  1.633930 -1.680658   \n",
       "2     0.113248 -0.607726 -0.947791  0.830851  0.998291  0.498321 -1.493958   \n",
       "3     1.223321 -0.479048 -1.925789  1.680377  0.021840 -1.453307  0.605559   \n",
       "4     0.160109  0.422684 -0.308029  0.227744  0.432854  0.608348  0.193832   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5245  1.157565 -0.142219  1.043992  1.144946  1.195423  0.248978 -1.505100   \n",
       "5246  1.424709  0.235910  1.356778  1.368099 -0.318862  1.039765 -0.986854   \n",
       "5247 -0.375687  1.524455  0.012514 -0.007917  0.073809 -0.906909 -1.254247   \n",
       "5248 -0.478238  1.666142  0.049609 -0.428752 -0.362771  1.798104 -0.214314   \n",
       "5249 -0.750874  0.267008 -0.155041 -0.179867 -0.155041 -0.303999 -0.279173   \n",
       "\n",
       "           f_7       f_8       f_9  ...    f_1191    f_1192    f_1193  \\\n",
       "0    -0.125239 -0.452284 -0.128052  ...  0.716084  0.060039  0.301279   \n",
       "1    -0.358146  0.166122 -1.656990  ...  0.829781  1.521941  1.347946   \n",
       "2     0.789572 -1.311018  0.848524  ...  0.616189 -1.035953  2.111387   \n",
       "3    -0.019024  1.065448  0.717341  ... -1.957863 -0.123384  1.505329   \n",
       "4     1.035091 -0.538868  0.778445  ...  1.441766  0.212572 -0.994721   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5245 -0.874137 -1.782724  0.261597  ... -0.255793 -0.154838  0.413029   \n",
       "5246 -0.330184 -1.383120  1.243559  ... -1.066107  0.881258 -0.488691   \n",
       "5247  1.606182  0.298557  0.053378  ... -0.968204 -1.233815  1.626613   \n",
       "5248  0.775400 -0.379267  0.725914  ... -1.121552 -0.379267 -0.593705   \n",
       "5249  1.731765  0.564925  1.508328  ... -0.850180  0.937321 -1.594972   \n",
       "\n",
       "        f_1194    f_1195    f_1196    f_1197    f_1198    f_1199  labels  \n",
       "0    -1.174846 -1.076498 -0.069452 -0.604012 -2.179176  0.558003       0  \n",
       "1     0.754505  1.330642 -0.754453  0.582956  0.252671  1.495870       1  \n",
       "2    -0.984415  1.148076 -1.433554  0.243372  0.170083  1.274795       1  \n",
       "3     0.660290 -1.769443 -0.547756 -0.568122  0.244645  0.982116       0  \n",
       "4     1.143999 -2.166923 -1.199248 -1.028636  0.752791  0.317169       0  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "5245 -0.482939 -1.277953 -0.445082  1.195423 -0.924614 -0.432462       0  \n",
       "5246 -1.281223 -1.213291  0.122692  1.175627 -1.145360  0.451026       0  \n",
       "5247 -0.191802  1.115823  0.380284 -0.293960  0.135104  1.381434       1  \n",
       "5248  0.049609  1.765114  0.313533 -0.329781 -1.220524  0.033114       1  \n",
       "5249  1.036626  1.582807  1.036626 -0.254346  0.664230  1.831071       1  \n",
       "\n",
       "[5250 rows x 1201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.pop('labels')  \n",
    "df['labels'] = labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1J3PzQNqriBn",
    "outputId": "adcdddc1-350e-4c46-e392-e773048cfeb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvIAfJvXsAF7",
    "outputId": "f4fa68a1-c5b5-4412-e824-a6f388b942f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3850\n",
       "1    1400\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LDBSSGH06H5W"
   },
   "outputs": [],
   "source": [
    "dft=pd.read_csv('./Generative AI Dataset/Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CeWE9OtHsMFC"
   },
   "outputs": [],
   "source": [
    "X_train=df.drop(columns=['labels'])\n",
    "y_train=df['labels']\n",
    "X_test=dft.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_train = StandardScaler()\n",
    "X_train = ss_train.fit_transform(X_train)\n",
    "ss_test = StandardScaler()\n",
    "X_test = ss_test.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = pd.DataFrame(predictions,columns=['labels'])\n",
    "# final['id']=0;\n",
    "# for i in range(len(final)):\n",
    "#     final.at[i, 'id'] = i + 1\n",
    "\n",
    "# final = final.rename(columns={'labels': 'id', 'id': 'labels'})\n",
    "# final['labels'], final['id'] = final['id'], final['labels']\n",
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final.to_csv('solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tExlURFUs7Zt"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0EUTj4Ot6EL",
    "outputId": "12b01283-eaf2-4ad5-c842-2378351783f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.60426628  0.99197232 -0.47376538 ... -1.03381538 -2.00978998\n",
      "   0.6148496 ]\n",
      " [-0.79041827  0.23144671 -0.90237498 ...  0.22311512  0.48813418\n",
      "   1.66050162]\n",
      " [-0.29301293 -0.77261046 -1.30495363 ... -0.13648457  0.40330259\n",
      "   1.41401959]\n",
      " ...\n",
      " [-0.81932242  1.59939616 -0.31422009 ... -0.70548846  0.36737287\n",
      "   1.53291384]\n",
      " [-0.92971308  1.75702021 -0.27594966 ... -0.74342066 -1.02508969\n",
      "   0.02963718]\n",
      " [-1.22319016  0.20051236 -0.48708444 ... -0.66353987  0.9108762\n",
      "   2.03422597]]\n",
      "**********\n",
      "[[-3.99766283  0.90850621 -0.86053999 ... -0.84374006 -0.32079492\n",
      "  -1.92542557]\n",
      " [-0.94547318  1.00570603  0.66536668 ...  1.70674983  0.90760882\n",
      "  -0.50419365]\n",
      " [ 0.77024325 -0.71683975  2.34062452 ... -1.00257203 -0.66977485\n",
      "   1.21399921]\n",
      " ...\n",
      " [ 0.90084345  1.3191385  -0.23422056 ...  0.89065631 -1.23610518\n",
      "   1.56326275]\n",
      " [ 0.67972755 -0.24436042  0.74884119 ...  0.71912829 -1.25167718\n",
      "   0.50212592]\n",
      " [-1.8138962  -0.65583759 -0.50604008 ...  0.06211087  0.15354715\n",
      "  -0.66619123]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled)\n",
    "print(\"**********\")\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "_2goIIOKviWD"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "fLDpHKqGx8T4"
   },
   "outputs": [],
   "source": [
    "from keras.layers.serialization import activation\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=1200, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PZzk5Qgyri9",
    "outputId": "bc7d8f88-3628-4b2c-b8e0-e04d7c6a5055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128)               153728    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,097\n",
      "Trainable params: 164,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "KYc-0OuBzBvl"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hUlL0_izdT_",
    "outputId": "0ea6f01b-a4a0-467b-9566-1e95aa9dabc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.4843 - accuracy: 0.7594 - val_loss: 0.0790 - val_accuracy: 0.9714\n",
      "Epoch 2/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8260 - val_loss: 0.0794 - val_accuracy: 0.9695\n",
      "Epoch 3/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8605 - val_loss: 0.0834 - val_accuracy: 0.9771\n",
      "Epoch 4/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.8978 - val_loss: 0.1040 - val_accuracy: 0.9790\n",
      "Epoch 5/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9261 - val_loss: 0.1263 - val_accuracy: 0.9752\n",
      "Epoch 6/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9469 - val_loss: 0.1328 - val_accuracy: 0.9790\n",
      "Epoch 7/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9566 - val_loss: 0.2064 - val_accuracy: 0.9752\n",
      "Epoch 8/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9653 - val_loss: 0.1857 - val_accuracy: 0.9771\n",
      "Epoch 9/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.1763 - val_accuracy: 0.9771\n",
      "Epoch 10/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9763 - val_loss: 0.1603 - val_accuracy: 0.9771\n",
      "Epoch 11/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9790 - val_loss: 0.1879 - val_accuracy: 0.9810\n",
      "Epoch 12/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 0.2018 - val_accuracy: 0.9771\n",
      "Epoch 13/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9848 - val_loss: 0.2511 - val_accuracy: 0.9771\n",
      "Epoch 14/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.2335 - val_accuracy: 0.9752\n",
      "Epoch 15/15\n",
      "148/148 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.3306 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled, y_train, epochs=15, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odLgHD3fzqZx",
    "outputId": "90b05980-ec34-47ed-ce58-476c076fbffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_log=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "zHU-cz6J0JGj"
   },
   "outputs": [],
   "source": [
    "y_pred=np.where(y_log>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "2v3heIR90o8H"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeHeXKSH05um",
    "outputId": "355da21b-a4de-4bb1-d07c-be57ec109877"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>2248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>2249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  labels\n",
       "0        1       0\n",
       "1        2       0\n",
       "2        3       0\n",
       "3        4       0\n",
       "4        5       0\n",
       "...    ...     ...\n",
       "2245  2246       0\n",
       "2246  2247       0\n",
       "2247  2248       1\n",
       "2248  2249       0\n",
       "2249  2250       1\n",
       "\n",
       "[2250 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.DataFrame(y_pred,columns=['labels'])\n",
    "final['id']=0;\n",
    "for i in range(len(final)):\n",
    "    final.at[i, 'id'] = i + 1\n",
    "\n",
    "final = final.rename(columns={'labels': 'id', 'id': 'labels'})\n",
    "final['labels'], final['id'] = final['id'], final['labels']\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ek3bhAqJ-I1K"
   },
   "outputs": [],
   "source": [
    "final.to_csv('solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
